{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Function OpenAI States to OPS States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_openai_weight(ops_state_dict, openai_state_dict, args):\n",
    "    state = deepcopy(ops_state_dict)\n",
    "    openai_weight_patterns = ['h.{n}.attn.c_attn.weight',\n",
    "                              'h.{n}.attn.c_proj.weight',\n",
    "                              'h.{n}.mlp.c_fc.weight',\n",
    "                              'h.{n}.mlp.c_proj.weight']\n",
    "    \n",
    "    # loading weight for attention and mlp layers for each block\n",
    "    # mismatch was due to use of Conv1D in openai implementation\n",
    "    for i in range(args.N):\n",
    "        for key in openai_weight_patterns:\n",
    "            ops_weight_key = 'transformer.decoder.decoder_blocks'+key.format(n=i)[1:]\n",
    "            state[ops_weight_key] = openai_state_dict[key.format(n=i)].transpose(-1,-2)\n",
    "            \n",
    "    state['transformer.embedding.embedding.weight'] = openai_state_dict['wte.weight']\n",
    "    state['transformer.pos_embedding.pos_embedding.weight'] = openai_state_dict['wpe.weight']\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading OPS GPT-2 Model State Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt2.model import get_gpt2\n",
    "from gpt2.utils import load_config\n",
    "\n",
    "args = load_config('config.yml')\n",
    "model = get_gpt2(args)\n",
    "ops_state_dic = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                      State         Shape\n",
       " 0                    transformer.embedding.embedding.weight  [50257, 768]\n",
       " 1            transformer.pos_embedding.pos_embedding.weight   [1024, 768]\n",
       " 2   transformer.decoder.decoder_blocks.0.attn.c_attn.weight   [2304, 768]\n",
       " 3     transformer.decoder.decoder_blocks.0.attn.c_attn.bias        [2304]\n",
       " 4   transformer.decoder.decoder_blocks.0.attn.c_proj.weight    [768, 768]\n",
       " 5     transformer.decoder.decoder_blocks.0.attn.c_proj.bias         [768]\n",
       " 6      transformer.decoder.decoder_blocks.0.mlp.c_fc.weight   [3072, 768]\n",
       " 7        transformer.decoder.decoder_blocks.0.mlp.c_fc.bias        [3072]\n",
       " 8    transformer.decoder.decoder_blocks.0.mlp.c_proj.weight   [768, 3072]\n",
       " 9      transformer.decoder.decoder_blocks.0.mlp.c_proj.bias         [768]\n",
       " 10         transformer.decoder.decoder_blocks.0.ln_1.weight         [768]\n",
       " 11           transformer.decoder.decoder_blocks.0.ln_1.bias         [768]\n",
       " 12         transformer.decoder.decoder_blocks.0.ln_2.weight         [768]\n",
       " 13           transformer.decoder.decoder_blocks.0.ln_2.bias         [768],\n",
       "                         State         Shape\n",
       " 146   transformer.ln_f.weight         [768]\n",
       " 147     transformer.ln_f.bias         [768]\n",
       " 148  projection.linear.weight  [50257, 768])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops_state_info = []\n",
    "for key in ops_state_dic.keys():\n",
    "    ops_state_info.append([key, list(ops_state_dic[key].size())])\n",
    "\n",
    "ops_df = pd.DataFrame(ops_state_info, columns=['State', 'Shape'])\n",
    "ops_df.head(14), ops_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading OpenAI GPT-2 Model State Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './assets/gpt2-pytorch_model.bin'\n",
    "openai_state_dic = torch.load(f=path, \n",
    "                               map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                     State               Shape\n",
       " 0               wte.weight        [50257, 768]\n",
       " 1               wpe.weight         [1024, 768]\n",
       " 2          h.0.ln_1.weight               [768]\n",
       " 3            h.0.ln_1.bias               [768]\n",
       " 4            h.0.attn.bias  [1, 1, 1024, 1024]\n",
       " 5   h.0.attn.c_attn.weight         [768, 2304]\n",
       " 6     h.0.attn.c_attn.bias              [2304]\n",
       " 7   h.0.attn.c_proj.weight          [768, 768]\n",
       " 8     h.0.attn.c_proj.bias               [768]\n",
       " 9          h.0.ln_2.weight               [768]\n",
       " 10           h.0.ln_2.bias               [768]\n",
       " 11     h.0.mlp.c_fc.weight         [768, 3072]\n",
       " 12       h.0.mlp.c_fc.bias              [3072]\n",
       " 13   h.0.mlp.c_proj.weight         [3072, 768]\n",
       " 14     h.0.mlp.c_proj.bias               [768],\n",
       "            State  Shape\n",
       " 158  ln_f.weight  [768]\n",
       " 159    ln_f.bias  [768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_state_info = []\n",
    "for key in openai_state_dic.keys():\n",
    "    openai_state_info.append([key, list(openai_state_dic[key].size())])\n",
    "\n",
    "openai_df = pd.DataFrame(openai_state_info, columns=['State', 'Shape'])\n",
    "openai_df.head(15), openai_df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming OpenAI Pretrained States into OPS States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops_pretrained_state_dic = load_openai_weight(ops_state_dic, openai_state_dic, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                      State         Shape\n",
       " 0                    transformer.embedding.embedding.weight  [50257, 768]\n",
       " 1            transformer.pos_embedding.pos_embedding.weight   [1024, 768]\n",
       " 2   transformer.decoder.decoder_blocks.0.attn.c_attn.weight   [2304, 768]\n",
       " 3     transformer.decoder.decoder_blocks.0.attn.c_attn.bias        [2304]\n",
       " 4   transformer.decoder.decoder_blocks.0.attn.c_proj.weight    [768, 768]\n",
       " 5     transformer.decoder.decoder_blocks.0.attn.c_proj.bias         [768]\n",
       " 6      transformer.decoder.decoder_blocks.0.mlp.c_fc.weight   [3072, 768]\n",
       " 7        transformer.decoder.decoder_blocks.0.mlp.c_fc.bias        [3072]\n",
       " 8    transformer.decoder.decoder_blocks.0.mlp.c_proj.weight   [768, 3072]\n",
       " 9      transformer.decoder.decoder_blocks.0.mlp.c_proj.bias         [768]\n",
       " 10         transformer.decoder.decoder_blocks.0.ln_1.weight         [768]\n",
       " 11           transformer.decoder.decoder_blocks.0.ln_1.bias         [768]\n",
       " 12         transformer.decoder.decoder_blocks.0.ln_2.weight         [768]\n",
       " 13           transformer.decoder.decoder_blocks.0.ln_2.bias         [768],\n",
       "                         State         Shape\n",
       " 146   transformer.ln_f.weight         [768]\n",
       " 147     transformer.ln_f.bias         [768]\n",
       " 148  projection.linear.weight  [50257, 768])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops_pretrained_state_info = []\n",
    "for key in ops_pretrained_state_dic.keys():\n",
    "    ops_pretrained_state_info.append([key, list(ops_pretrained_state_dic[key].size())])\n",
    "\n",
    "ops_pretrained_df = pd.DataFrame(ops_pretrained_state_info, columns=['State', 'Shape'])\n",
    "ops_pretrained_df.head(14), ops_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops_pretrained_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading OpenAI Pretrained States into OPS States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(ops_pretrained_state_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./assets/ops_gpt2_pretrained_states.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
